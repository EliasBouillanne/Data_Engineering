{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elasticsearch est un moteur de recherche temps réel et Open Source. \n",
    "Il possède de nombreux avantages : \n",
    "- il met en place une API RESTful.\n",
    "- il est distribué, ce qui lui permet d'être tolérant aux pannes.\n",
    "- il est basé sur le moteur d'indexation d'Apache Lucène.\n",
    "- utilise le format JSON pour le stockage\n",
    "- permet de faire de la recherche en texte libre. \n",
    "\n",
    "Il est utilisé dans de nombreuses entreprises pour faire de la recherche textuelle dans des documents ou alors traiter des tera de logs. \n",
    "\n",
    "Dans ce cours nous allons aborder deux technologies, ElasticSearch et Kibana. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Near Realtime (NRT)` : La plupart des anciens moteurs de recherche devaient processer et indexer les documents pour qu'ils puissent être recherchés. ElasticSearch permet de rechercher les nouveaux documents presque instantanément.  \n",
    "\n",
    "\n",
    "- `Document` : Le document est l'unité de base  qui peut être indexé dans ElasticSearch. Un document est représenté au format JSON. On peut stocker autant de document que l'on souhaite dans un index. Un document est un ensemble de données clés-valeurs.   \n",
    "\n",
    "\n",
    "- `Index` : Un index est une collection de documents qui ont des caractéristiques similaires. Un index est identifié par un nom. On peut créer autant d'index que l'on veut.   \n",
    "\n",
    "\n",
    "- `Node` : Un Node (ou noeud en francais) est un serveur qui fait parti d'un cluster de plusieurs noeuds. Un noeud stocke les données et est optimisé pour retrouver les données.   \n",
    "\n",
    "\n",
    "- `Cluster` : Un cluster est un ensemble de noeud qui communiquent entre eux.  Un cluster peut contenir autant de noeuds que l'on veut.   \n",
    "\n",
    "\n",
    "- `Shards` :  Un index peut être tellement gros que la donnée des documents est plus importante que la capacité de stockage d'un node et donc d'un serveur. Pour pallier ce problème ElasticSearch met en place une méthode pour découper la données des index en des nombreuses petites parties qui sont appelés des shards. Chaque shard est stocké sur un noeud différents. \n",
    "\n",
    "    Cette technique est intéressante car elle permet de scaler horizontalement notre cluster (ie: augmenter le nombre de machines et donc de noeuds)  \n",
    "    \n",
    "\n",
    "- `Replicas` : Comme chaque noeud ne contient pas l'intégralité des données, on pourrait penser que si un noeud tombe en panne, une partie des données serait perdue. ElasticSearch met en place une technique de réplication qui permet de stocker ces différents shards sur plusieurs noeuds. C'est la **réplication**.  \n",
    "    \n",
    "    Cette technique est particulièrement intéressante puisqu'elle permet de palier la panne de shards ou de noeuds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Play "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "LOCAL = True\n",
    "\n",
    "es_client = Elasticsearch(hosts=[\"localhost\" if LOCAL else \"elasticsearch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.ping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour indexer des documents, il suffit d'appeler la méthode `index` du client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = {\n",
    "    \"name\":\"Decision Trees\", \n",
    "    \"description\":\"A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance-event outcomes, resource costs, and utility. Take a look at the image to get a sense of how it looks like.\",\n",
    "    \"algo_type\":\"Supervised Learning\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created\n"
     ]
    }
   ],
   "source": [
    "res = es_client.index(index=\"algorithms\", doc_type='algo', id=1, body=document)\n",
    "print(res['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le document à été créé avec succès, on peut maintenant le récupérer via son index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo_type': 'Supervised Learning',\n",
      " 'description': 'A decision tree is a decision support tool that uses a '\n",
      "                'tree-like graph or model of decisions and their possible '\n",
      "                'consequences, including chance-event outcomes, resource '\n",
      "                'costs, and utility. Take a look at the image to get a sense '\n",
      "                'of how it looks like.',\n",
      " 'name': 'Decision Trees'}\n"
     ]
    }
   ],
   "source": [
    "res = es_client.get(index=\"algorithms\", doc_type='algo', id=1)\n",
    "pprint.pprint(res[\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    {\n",
    "    \"name\":\"Naive Bayes Classification\", \n",
    "    \"description\":\"Naive Bayes classifiers are a family of simple probabilistic classifiers based on applying Bayes’ theorem with strong (naive) independence assumptions between the features. The featured image is the equation — with P(A|B) is posterior probability, P(B|A) is likelihood, P(A) is class prior probability, and P(B) is predictor prior probability.\",\n",
    "    \"algo_type\":\"Supervised Learning\"\n",
    "    },    {\n",
    "    \"name\":\"Logistic Regression\", \n",
    "    \"description\":\"Logistic regression is a powerful statistical way of modeling a binomial outcome with one or more explanatory variables. It measures the relationship between the categorical dependent variable and one or more independent variables by estimating probabilities using a logistic function, which is the cumulative logistic distribution.\",\n",
    "    \"algo_type\":\"Supervised Learning\"\n",
    "},    {\n",
    "    \"name\":\"Principal Component Analysis\", \n",
    "    \"description\":\"PCA is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components.\",\n",
    "    \"algo_type\":\"Unsupervised Learning\"\n",
    "},    {\n",
    "    \"name\":\"Singular Value Decomposition\", \n",
    "    \"description\":\"In linear algebra, SVD is a factorization of a real complex matrix. For a given m * n matrix M, there exists a decomposition such that M = UΣV, where U and V are unitary matrices and Σ is a diagonal matrix.\",\n",
    "    \"algo_type\":\"Unsupervised Learning\"\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on ne précise pas l'ID lors de l'indexation, ElasticSearch se charge d'en trouver un automatiquement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    res = es_client.index(index=\"algorithms\", doc_type='algo', id=None, body=doc)\n",
    "    print(res[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On récupère maintenant tous les éléments de l'index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = es_client.search(index=\"algorithms\", body={\"query\": {\"match_all\": {}}})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La réponse nous donne des informations sur le temps d'exécution de la requête le nombre de documents correspondant à la requête et l'ensemble des documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{result['hits']['total']} documents correspondent à la requêtes qui a pris {result['took']}ms\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons maintenant tous les documents : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for hit in result['hits']['hits']:\n",
    "    print(\"Name : {name}\\n description : {description} \\n Type : {algo_type}\\n\".format(**hit['_source']))\n",
    "    print(\"******************\")\n",
    "    ids.append(hit[\"_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour supprimer un document il suffit d'appeler la méthode `delete`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client.delete(index=\"algorithms\", doc_type=\"algo\", id=ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = es_client.search(index=\"algorithms\", body={\"query\": {\"match_all\": {}}})\n",
    "f\"{result['hits']['total']} documents correspondent à la requêtes qui a pris {result['took']}ms\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faisons des choses un peu plus intéressantes maintenant.   \n",
    "\n",
    "Dans le répertoire `data/` il y a les données de 5000 films de la base de TMDb. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de commencer il faut nettoyer un peu les données du fichier csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "df_movies = pd.read_csv(\"./data/tmdb_5000_movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(l):\n",
    "    return [elt[\"name\"] for elt in json.loads(l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On nettoie alors la donnée des colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"genres\", \"keywords\", \"production_countries\", \"spoken_languages\"]:\n",
    "    df_movies.loc[:,col] = df_movies.loc[:,col].apply(clean_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour indexer les documents il nous faut une liste de dictionnaires. Pour cela on peut utiliser la méthode de pandas `to_dict` avec le paramètre `orient=records`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df_movies.fillna(\"\").to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'budget': 237000000,\n",
       "  'genres': ['Action', 'Adventure', 'Fantasy', 'Science Fiction'],\n",
       "  'homepage': 'http://www.avatarmovie.com/',\n",
       "  'id': 19995,\n",
       "  'keywords': ['culture clash',\n",
       "   'future',\n",
       "   'space war',\n",
       "   'space colony',\n",
       "   'society',\n",
       "   'space travel',\n",
       "   'futuristic',\n",
       "   'romance',\n",
       "   'space',\n",
       "   'alien',\n",
       "   'tribe',\n",
       "   'alien planet',\n",
       "   'cgi',\n",
       "   'marine',\n",
       "   'soldier',\n",
       "   'battle',\n",
       "   'love affair',\n",
       "   'anti war',\n",
       "   'power relations',\n",
       "   'mind and soul',\n",
       "   '3d'],\n",
       "  'original_language': 'en',\n",
       "  'original_title': 'Avatar',\n",
       "  'overview': 'In the 22nd century, a paraplegic Marine is dispatched to the moon Pandora on a unique mission, but becomes torn between following orders and protecting an alien civilization.',\n",
       "  'popularity': 150.437577,\n",
       "  'production_companies': '[{\"name\": \"Ingenious Film Partners\", \"id\": 289}, {\"name\": \"Twentieth Century Fox Film Corporation\", \"id\": 306}, {\"name\": \"Dune Entertainment\", \"id\": 444}, {\"name\": \"Lightstorm Entertainment\", \"id\": 574}]',\n",
       "  'production_countries': ['United States of America', 'United Kingdom'],\n",
       "  'release_date': '2009-12-10',\n",
       "  'revenue': 2787965087,\n",
       "  'runtime': 162.0,\n",
       "  'spoken_languages': ['English', 'Español'],\n",
       "  'status': 'Released',\n",
       "  'tagline': 'Enter the World of Pandora.',\n",
       "  'title': 'Avatar',\n",
       "  'vote_average': 7.2,\n",
       "  'vote_count': 11800},\n",
       " {'budget': 300000000,\n",
       "  'genres': ['Adventure', 'Fantasy', 'Action'],\n",
       "  'homepage': 'http://disney.go.com/disneypictures/pirates/',\n",
       "  'id': 285,\n",
       "  'keywords': ['ocean',\n",
       "   'drug abuse',\n",
       "   'exotic island',\n",
       "   'east india trading company',\n",
       "   \"love of one's life\",\n",
       "   'traitor',\n",
       "   'shipwreck',\n",
       "   'strong woman',\n",
       "   'ship',\n",
       "   'alliance',\n",
       "   'calypso',\n",
       "   'afterlife',\n",
       "   'fighter',\n",
       "   'pirate',\n",
       "   'swashbuckler',\n",
       "   'aftercreditsstinger'],\n",
       "  'original_language': 'en',\n",
       "  'original_title': \"Pirates of the Caribbean: At World's End\",\n",
       "  'overview': 'Captain Barbossa, long believed to be dead, has come back to life and is headed to the edge of the Earth with Will Turner and Elizabeth Swann. But nothing is quite as it seems.',\n",
       "  'popularity': 139.082615,\n",
       "  'production_companies': '[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"name\": \"Jerry Bruckheimer Films\", \"id\": 130}, {\"name\": \"Second Mate Productions\", \"id\": 19936}]',\n",
       "  'production_countries': ['United States of America'],\n",
       "  'release_date': '2007-05-19',\n",
       "  'revenue': 961000000,\n",
       "  'runtime': 169.0,\n",
       "  'spoken_languages': ['English'],\n",
       "  'status': 'Released',\n",
       "  'tagline': 'At the end of the world, the adventure begins.',\n",
       "  'title': \"Pirates of the Caribbean: At World's End\",\n",
       "  'vote_average': 6.9,\n",
       "  'vote_count': 4500}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour éviter de faire plein de petits appels à ElasticSearch pour indexer les 5000 films on peut utiliser un helper `bulk` pour indexer tous les documents d'un seul coup et éviter les appels réseaux qui sont très couteux en temps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch.helpers import bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4803, [])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_data(documents):\n",
    "    for docu in documents:\n",
    "        yield {\n",
    "            \"_index\": \"movies\",\n",
    "            \"_type\": \"movie\",\n",
    "            \"_source\": {k:v if v else None for k,v in docu.items()},\n",
    "        }\n",
    "\n",
    "bulk(es_client, generate_data(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut utiliser l'interface http pour vérifier que les index sont bien à jours. L'index `movies` est présent on peut aussi voir le nombre de documents et la taille en mémoire.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:9200/_cat/indices?v #!curl http://elasticsearch:9200/_cat/indices?v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir aussi quelques documents avec le endpoint HTTP suivant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:9200/movies/_search #!curl http://elasticsearch:9200/movies/_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kibana "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est le moment de commencer à utiliser Kibana. Kibana est un soft de la suite ELK (ElasticSearch, Kibana, Logstash) qui permet de gérer de façon graphique les données dans les index ElasticSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'onglet `Management`, il faut spécifier à Kibana d'aller chercher un index spécifique sur ElasticSearch. Aller dans `Create index pattern` et taper les premières lettres du nom de l'index que vous voulez parcourir. Ici `movies`, vous verrez alors la page suivante, référençant l'intégralité des champs de l'index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"./img/index_pattern.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez ensuite aller dans l'onglet `Discover` pour voir un apperçu des documents que vous venez d'indexer. Vous pouvez aussi, sur la droite, appliquer des filtres pour faire des requêtes simples sur vos données. Ici on appliquera un filtre sur le genre `Comedy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"./img/discover.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez aller ensuite dans l'onglet `Visualize` pour commencer à jouer avec les graphiques. Par exemple on peut créer un histograme des budgets des différents films. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"./img/budget.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou encore des genres des différents films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"./img/gender.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retournons maintenant un peu dans notre code pour commencer à utiliser ses données. Il va maintenant falloir se plonger dans les requêtes ElasticSearch. Ce n'est pas la choise la plus aisée, elles deviennent vite illisibles et complexes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = {\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette requête simple permet de récupérer l'intégralité des documents d'un index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = {\n",
    "  \"query\": {\n",
    "    \"term\" : { \n",
    "        \"title\" : \"superman\"} \n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette seconde requête permet de récupérer tous les documents dont le titre contient `SuperMan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = es_client.search(index=\"movies\", body=QUERY)\n",
    "[elt['_source']['title'] for elt in result[\"hits\"][\"hits\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut maintenant chercher tous les films contenant `SuperMan` mais qui ne contiennent pas `Batman`. Pour cela on est forcé d'utilisé une requête composée appelée `bool query`  elle permet de transformer chaque requête en un filtre booléen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = {\n",
    "  \"query\": {\n",
    "    \"bool\" : {\n",
    "      \"must\" : {\n",
    "        \"term\" : { \"title\" : \"superman\" }\n",
    "      },\n",
    "      \"must_not\" : {\n",
    "                  \"term\" : { \"title\" : \"batman\" }\n",
    "      }\n",
    "  }\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = es_client.search(index=\"movies\", body=QUERY)\n",
    "[elt['_source']['title'] for elt in result[\"hits\"][\"hits\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut encore réduire les resultats en filtrant sur le budget du film. On veut en plus des films de SuperMan sans Batman récupérer les films qui on eu un budget de plus de ou égal à 20M  et moins de 55M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = {\n",
    "  \"query\": {\n",
    "    \"bool\" : {\n",
    "      \"must\" : [\n",
    "          {\n",
    "        \"term\" : { \"title\" : \"superman\" }},\n",
    "        {\"range\" : {\n",
    "          \"budget\" : { \"gte\" : 20000000, \"lt\" : 55000000 }\n",
    "        }}\n",
    "      ],\n",
    "      \"must_not\" : {\n",
    "                  \"term\" : { \"title\" : \"batman\" }\n",
    "      }\n",
    "  }\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = es_client.search(index=\"movies\", body=QUERY)\n",
    "{elt['_source']['title']:elt['_source']['budget']  for elt in result[\"hits\"][\"hits\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on veut faire une recherche dans plusieurs champs de chaque document de l'index on peut faire une requête de `multi_match`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = {\n",
    "  \"query\": {\n",
    "    \"multi_match\" : {\n",
    "      \"query\":    \"Smith\",\n",
    "      \"fields\": [ \"title\", \"overview\" ] \n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = es_client.search(index=\"movies\", body=QUERY)\n",
    "[elt['_source']['title']  for elt in result[\"hits\"][\"hits\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut vouloir trier les résultats selon la popularité par exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = {\n",
    "  \"query\": {\n",
    "    \"multi_match\" : {\n",
    "      \"query\":    \"Smith\",\n",
    "      \"fields\": [ \"title\", \"overview\" ] \n",
    "    }\n",
    "  },\n",
    "    \"sort\" : [\n",
    "        { \"popularity\" : {\"order\" : \"desc\"}}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = es_client.search(index=\"movies\", body=QUERY)\n",
    "{elt['_source']['title']:elt['_source']['popularity']  for elt in result[\"hits\"][\"hits\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ElasticSearch gère aussi bien les dates. On peut vouloir trier par date de sortie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = {\n",
    "  \"query\": {\n",
    "    \"multi_match\" : {\n",
    "      \"query\":    \"Smith\",\n",
    "      \"fields\": [ \"title\", \"overview\" ] \n",
    "    }\n",
    "  },\n",
    "    \"sort\" : [\n",
    "        { \"release_date\" : {\"order\" : \"desc\"}}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = es_client.search(index=\"movies\", body=QUERY)\n",
    "{elt['_source']['title']:elt['_source']['release_date']  for elt in result[\"hits\"][\"hits\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les aggregations sont des requêtes complexes mais qui permettent de faire des opérations très rapides sur les données. \n",
    "La syntaxe devient très vite complexe. Par exemple, pour récupérer le nombre de film par genre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = {\n",
    "    \"aggs\": {\n",
    "    \"count_gender\": {\n",
    "      \"terms\": {\n",
    "        \"field\": \"genres.keyword\",\n",
    "        \"size\": 5,\n",
    "        \"order\": {\n",
    "          \"_count\": \"desc\"\n",
    "        }\n",
    "      }\n",
    "        }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = es_client.search(index=\"movies\", body=QUERY)\n",
    "result[\"aggregations\"][\"count_gender\"][\"buckets\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le paramètre size permet de récupérer les N premières aggrégations.\n",
    "\n",
    "Ensuite si on veut aller plus loin on peut vouloir récupérer la moyenne des budgets par genre. Il faut intégrer un nouveau niveau d'aggregation. Pour cela on utilise la syntaxe suivante. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = {\n",
    "    \"aggs\": {\n",
    "        \"count_gender\": {\n",
    "            \"terms\": {\n",
    "                \"field\": \"genres.keyword\",\n",
    "                \"size\": 3,\n",
    "                \"order\": {\n",
    "                    \"average_budget\": \"desc\"\n",
    "                }\n",
    "            },\n",
    "            \"aggs\": {\n",
    "                \"average_budget\":{\n",
    "                    \"avg\" : {\n",
    "                        \"field\" : \"budget\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = es_client.search(index=\"movies\", body=QUERY)\n",
    "result[\"aggregations\"][\"count_gender\"][\"buckets\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credits = pd.read_csv(\"data/tmdb_5000_credits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Nettoyer les données de la DataFrame d'acteurs comme précédement.   \n",
    "2) Merger les deux DataFrame en utilisant l'identifiant du film.   \n",
    "3) Créer un nouvel Index `augmented_movies` similaire à l'index précédant mais en ajoutant les données des acteurs.     \n",
    "4) Créer une fonction permettant de trouver tous les films d'un acteur.   \n",
    "5) Trouver quel acteur à jouer dans les films avec les plus gros budgets. \n",
    "6) Réaliser, sur Kibana, 3 graphiques de votre choix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MongoDB():\n",
    "    def __init__(self):\n",
    "        self.client = MongoClient()\n",
    "        self.db = self.client['Vidal']\n",
    "    \n",
    "    def find(self, collection):\n",
    "        return self.db[collection].find()\n",
    "    \n",
    "    def collection(self):\n",
    "        return self.db.list_collection_names()\n",
    "    \n",
    "class ElasticsearchDB():\n",
    "    def __init__(self):\n",
    "        self.mongo = MongoDB()\n",
    "        self.client = Elasticsearch()\n",
    "    \n",
    "    def index_bulk(self):\n",
    "        for collection in self.mongo.collection():\n",
    "            bulk(client=self.client, actions=self.index_mongo(collection), request_timeout=30)\n",
    "    \n",
    "    def index_mongo(self, collection):\n",
    "        cursor = self.mongo.find(collection)\n",
    "        for item in cursor:\n",
    "            _id = str(item['_id'])\n",
    "            del item['_id']\n",
    "            action = {\n",
    "                '_op_type': 'index',\n",
    "                \"_index\" : collection,\n",
    "                \"_type\"  : collection+\"_document\",\n",
    "                \"_id\"    : _id,\n",
    "                \"_source\": item,\n",
    "                \"_size\": {\"enabled\": 'true'}\n",
    "            }\n",
    "            yield action\n",
    "    \n",
    "    #DEUXIEME POSSIBILITE\n",
    "\n",
    "\n",
    "    def search_insubstance(self, substance):\n",
    "        query = json.dumps({\n",
    "          \"query\": {\n",
    "            \"bool\" : {\n",
    "              \"must\" : [\n",
    "                  {\n",
    "                \"term\" : { \"nom_substance\" : substance }},\n",
    "              ]\n",
    "          }\n",
    "        }\n",
    "        })\n",
    "        #response = requests.get(uri, data=query)\n",
    "        #results = json.loads(response.text)\n",
    "    \n",
    "        result = client.search(index=\"substance_items\", body=query)\n",
    "        return result\n",
    "\n",
    "\n",
    "    def search_inmedicament(self, substance, excipient=False):\n",
    "        if excipient==False:\n",
    "            query = json.dumps({\n",
    "              \"query\": {\n",
    "                \"bool\" : {\n",
    "                  \"must_not\" : {\n",
    "                          \"term\" : { \"excipient\" : excipient }\n",
    "                  }\n",
    "              }\n",
    "            }\n",
    "            })\n",
    "        else:\n",
    "            query = json.dumps({\n",
    "              \"query\": {\n",
    "                \"bool\" : {\n",
    "                  \"must_not\" : {\n",
    "                          \"term\" : { \"excipient\" : excipient }\n",
    "                  },\n",
    "                  \"should\": [\n",
    "                    \"bool\": {\n",
    "                       \"must\": {[\n",
    "                        { \"term\": { \"substance\": substance }}\n",
    "                       ]}\n",
    "                    }\n",
    "                  ]\n",
    "                }\n",
    "              }\n",
    "            })\n",
    "            \n",
    "    \n",
    "        result = client.search(index=\"medicament_items\", body=query)\n",
    "        return result\n",
    "\n",
    "\n",
    "    def format_results(self, result, content):\n",
    "        \"\"\"Print results nicely:\n",
    "        doc_id) content\n",
    "        \"\"\"\n",
    "        data = [doc for doc in result['hits']['hits']]\n",
    "        for doc in data:\n",
    "            print(\"%s\" % (doc['_source'][content]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-7ea6c3eb4938>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melastic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_insubstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"clomifène\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#elastic.format_results(r, \"fiche\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmm\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0melastic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_inmedicament\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"clomifène\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"amidon soluble\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-55-155abd919c99>\u001b[0m in \u001b[0;36msearch_inmedicament\u001b[1;34m(self, substance, excipient)\u001b[0m\n\u001b[0;32m     76\u001b[0m                     \"bool\": {\n\u001b[0;32m     77\u001b[0m                        \"must\": {[\n\u001b[1;32m---> 78\u001b[1;33m                         \u001b[1;33m{\u001b[0m \u001b[1;34m\"term\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m \u001b[1;34m\"substance\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msubstance\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m                        ]}\n\u001b[0;32m     80\u001b[0m                     }\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "elastic = ElasticsearchDB()\n",
    "#elastic.index_bulk()\n",
    "ss = elastic.search_insubstance(\"clomifène\")\n",
    "#elastic.format_results(r, \"fiche\")\n",
    "mm =elastic.search_inmedicament(\"clomifène\", \"amidon soluble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nom_medicament': 'PERGOTIME 50 mg cp séc', 'descriptif': {'liste': 'liste 1', 'cip': '8340093280098', 'modalités_de_conservation': 'avant ouverture : durant 4 ans.', 'remboursement': 'nr', 'agréé_aux_collectivités': 'non', 'commercialisé': 'non', 'modèle_hospitalier': 'non'}, 'excipient': ['cellulose', 'amidon de maïs', 'silice', 'magnésium stéarate', 'carboxyméthylamidon', 'lactose'], 'lien_medicament': 'https://www.vidal.fr/Medicament/pergotime_50_mg_cp_sec-12986.htm', 'substance': ['Clomifène citrate']}\n",
      "{'nom_medicament': 'CLOMID 50 mg cp', 'descriptif': {'agréé_aux_collectivités': 'oui', 'liste': 'liste 1', 'cip': '9340093262338', 'remboursement': '65%', 'commercialisé': 'oui', 'modalités_de_conservation': \"avant ouverture : durant 36 mois (conserver à l'abri de la chaleur, conserver à l'abri de la lumière, conserver à l'abri de l'humidité).\", 'modèle_hospitalier': 'non'}, 'excipient': ['amidon de maïs', 'amidon soluble', 'magnésium stéarate', 'fer jaune oxyde', 'saccharose', 'lactose monohydrate'], 'lien_medicament': 'https://www.vidal.fr/Medicament/clomid_50_mg_cp-4095.htm', 'substance': ['Clomifène citrate']}\n"
     ]
    }
   ],
   "source": [
    "data = [doc for doc in mm['hits']['hits']]\n",
    "for doc in data:\n",
    "    print(\"%s\" % (doc['_source']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-38-0bfdd7bb4a5e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-38-0bfdd7bb4a5e>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    for s, m in zip(ss[\"hits\"][\"hits\"], mm[\"hits\"][\"hits\"]]\u001b[0m\n\u001b[1;37m                                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for s, m in zip(ss[\"hits\"][\"hits\"], mm[\"hits\"][\"hits\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "health status index      uuid                   pri rep docs.count docs.deleted store.size pri.store.size\n",
      "yellow open   algorithms CsF-T8sJSTqzwL5dV8Ejzg   5   1          1            0      7.1kb          7.1kb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   212  100   212    0     0   1503      0 --:--:-- --:--:-- --:--:--  1503\n",
      "curl: (3) <url> malformed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0curl: (6) Could not resolve host: elasticsearch\n"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:9200/_cat/indices?v #!curl http://elasticsearch:9200/_cat/indices?v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from elasticsearch import Elasticsearch\n",
    "#es = Elasticsearch()\n",
    "#es.indices.delete(index='substance_items', ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Elasticsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = {\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'took': 6, 'timed_out': False, '_shards': {'total': 10, 'successful': 10, 'skipped': 0, 'failed': 0}, 'hits': {'total': 0, 'max_score': None, 'hits': []}}\n"
     ]
    }
   ],
   "source": [
    "#PREMIERE POSSIBILITE\n",
    "\n",
    "QUERY = {\n",
    "  \"query\": {\n",
    "    \"bool\" : {\n",
    "      \"must\" : [\n",
    "          {\n",
    "        \"term\" : { \"substance_items.nom_substance\" : \"lysozyme\" }},\n",
    "      ],\n",
    "      \"must_not\" : {\n",
    "                  \"term\" : { \"medicament_items.excipient\" : \"amidon\" }\n",
    "      }\n",
    "  }\n",
    "}\n",
    "}\n",
    "\n",
    "result = client.search(index=\"substance_items,medicament_items\", body=QUERY)\n",
    "[elt['_source']['liste_medicament'] for elt in result['hits']['hits']]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEUXIEME POSSIBILITE\n",
    "\n",
    "\n",
    "def search_insubstance(substance):\n",
    "    query = json.dumps({\n",
    "      \"query\": {\n",
    "        \"bool\" : {\n",
    "          \"must\" : [\n",
    "              {\n",
    "            \"term\" : { \"nom_substance\" : substance }},\n",
    "          ]\n",
    "      }\n",
    "    }\n",
    "    })\n",
    "    #response = requests.get(uri, data=query)\n",
    "    #results = json.loads(response.text)\n",
    "    \n",
    "    result = client.search(index=\"substance_items\", body=query)\n",
    "    return results\n",
    "\n",
    "\n",
    "def search_inmedicament(excipient):\n",
    "    query = json.dumps({\n",
    "      \"query\": {\n",
    "        \"bool\" : {\n",
    "          \"must_not\" : {\n",
    "                  \"term\" : { \"excipient\" : excipient }\n",
    "          }\n",
    "      }\n",
    "    }\n",
    "    })\n",
    "    \n",
    "    result = client.search(index=\"medicament_items\", body=query)\n",
    "    return results\n",
    "\n",
    "\n",
    "def format_results(results, content):\n",
    "    \"\"\"Print results nicely:\n",
    "    doc_id) content\n",
    "    \"\"\"\n",
    "    data = [doc for doc in results['hits']['hits']]\n",
    "    for doc in data:\n",
    "        print(\"%s\" % (doc['_source'][content]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. On trouve une méthode qui nous permet de faire une query sur deux collections en même temps. C'est ce que j'ai tenté dans la première possibilité.\n",
    "\n",
    "2. On créée deux fonctions qui récupère le résultat de nos deux query (à savoir une pour chercher la liste des médicaments qui contiennent la substance et une deuxième pour récupérer les médicaments ne contenant pas l'excipient prohibé), et on merge nos deux résultats dans une liste (par exemple)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
